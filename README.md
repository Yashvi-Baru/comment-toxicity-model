# Comment Toxicity Model

## Overview

The **Comment Toxicity Model** leverages Machine Learning (ML) and Natural Language Processing (NLP) to detect harassment and hate speech in online comments, ensuring safer online communities. The model performs real-time binary classification and identifies toxicity across six categories:
- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

## Technologies Used
- Python
- TensorFlow
- Keras
- Pandas
- Scikit-learn
- Gradio

## Reference
This project was inspired by Nicholas Renotteâ€™s YouTube tutorial: [Building a Toxic Comment Detection Model](https://www.youtube.com/watch?v=ZUqB-luawZg&ab_channel=NicholasRenotte).

